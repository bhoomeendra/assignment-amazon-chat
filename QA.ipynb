{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bbaa7ee-bda6-41cf-85a0-bce00d60dc24",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "1. Question Answer pair generation using Llama 2 with few short prompting for RAG evalution\n",
    "2. Chunking the conversation Data\n",
    "3. Vector DB intialized\n",
    "4. RAG Pipline defined\n",
    "5. Generating answer for the Questions\n",
    "6. Evalution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a249779-0ebe-454a-8068-85244cc66a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb6a66ca-131a-4f3c-b209-5765c0855b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset/conversation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2cb84a8-864f-4410-896b-4e810476cc0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation</th>\n",
       "      <th>conv_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Are you a fan of Google or Microsoft?\\nBoth ar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>do you like dance?\\nYes  I do. Did you know Br...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey what's up do use Google very often?I reall...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hi!  do you like to dance?\\nI love to dance a ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>do you like dance?\\nI love it. Did you know Br...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        conversation  conv_id\n",
       "0  Are you a fan of Google or Microsoft?\\nBoth ar...        1\n",
       "1  do you like dance?\\nYes  I do. Did you know Br...        2\n",
       "2  Hey what's up do use Google very often?I reall...        3\n",
       "3  Hi!  do you like to dance?\\nI love to dance a ...        4\n",
       "4  do you like dance?\\nI love it. Did you know Br...        5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b130638c-c97f-4f9b-b900-50d8a0e13a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8daf2bd-fa17-4307-8b74-9cff4933d135",
   "metadata": {},
   "source": [
    "### Pipline Initalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8bcb42e-7799-45a2-8a39-e7ce0f2eebf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abf6ddf24fa84531a99a1105082834b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_name,\n",
    "    device_map=\"auto\",\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    max_length=4000,\n",
    "    do_sample=True,\n",
    "    top_k=10,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9669e1-4e44-4f2a-84b5-37efd4f97948",
   "metadata": {},
   "source": [
    "### Question Answer pair generation using Llama 2 with few short prompting for RAG evalution\n",
    "\n",
    "As we dont have any question we are generating the question and answer pairs from the first 50 converstation we have generated about 100 qa pairs. To do so we have used Llama 2 fine with few short prompting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67db4737-2224-42c3-8092-ffb71cdc32c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████████████▋                                                                                                | 10/49 [01:39<06:23,  9.84s/it]/home2/sisodiya.bhoomendra/venvs/python3.9_global/lib/python3.9/site-packages/transformers/pipelines/base.py:1083: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [07:28<00:00,  9.16s/it]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import ipdb\n",
    "\n",
    "q = defaultdict(list)\n",
    "a = defaultdict(list)\n",
    "for i in tqdm(range(1,50)):\n",
    "    prompt = f\"\"\"<s>[INST] Generates only 3 question and answer pairs bases on the converstation provided in triple back ticks ```{data.conversation[0]}``` \\\n",
    "use <question> and <ans> tags to indicate them:\n",
    "\n",
    "<question> Do you like cats?\n",
    "<ans> The cat is referred as domestic cat and wild cat. They make our world very clean from rats!\n",
    "<question> Why do you think cats spend a lot of their time sleeping?\n",
    "<ans> Cats hear the sounds too faint or too high frequency human ears can hear.\n",
    "<question> What are some of the services provided by Google?\n",
    "<ans> Google provides online related services and products, which includes online ads, search engine and cloud computing.\n",
    "[/INST]</s>\n",
    "\n",
    "<s>[INST] Generates only 3 question and answer pairs bases on the converstation provided in triple back ticks ```{data.conversation[i]}``` \\\n",
    "use <question> and <ans> tags to indicate them:\n",
    "\n",
    "\"\"\"\n",
    "    seq = pipeline(prompt) \n",
    "    x = seq[0]['generated_text'].split(prompt)\n",
    "    for elm in x[1].split(\"\\n\"):\n",
    "        if elm.find(\"<question>\")!=-1:\n",
    "            q[i+1].append(elm)\n",
    "        elif elm.find(\"<ans>\")!=-1:\n",
    "            a[i+1].append(elm)\n",
    "    # print(q,a)\n",
    "    # ipdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7595765b-9931-49f0-b12a-0a3e68f3b3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ques,anss,conv_id = [],[],[]\n",
    "for k in q.keys():\n",
    "    for que,ans in zip(q[k],a[k]):\n",
    "        if ans is not None:\n",
    "            ques.append(que)\n",
    "            anss.append(ans)\n",
    "            conv_id.append(k)\n",
    "\n",
    "pd.DataFrame({\"Question\":ques,\"Answer\":anss,\"Conv_id\":conv_id}).to_csv(\"dataset/gen_qa_pair.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0793e1aa-f613-4da7-9120-3cef01a9599f",
   "metadata": {},
   "source": [
    "### Chunking the converstions\n",
    "A coversation is made of messages and we have made chucks of 6 messages i.e a combination of 6 messages will be used to get an embedding in the vector DB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3e864168-616f-4021-a378-edbcb8d42836",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "cov_ids = []\n",
    "\n",
    "for _,x in data.iterrows():\n",
    "    \n",
    "    lines = x.conversation.split(\"\\n\")\n",
    "    for i in range(0,len(lines),6):\n",
    "        docs.append(\"\\n\".join(lines[i:i+6]).strip(\"\\n\"))\n",
    "        cov_ids.append(str(x.conv_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "df512a64-82b8-4b47-84bb-ddc827a8dafe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(409, 409)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs),len(cov_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06044eef-5b6b-41df-a9ad-c185a2ae10cb",
   "metadata": {},
   "source": [
    "### Vector DB intialized\n",
    "\n",
    "We initalized the vector DB with the chucked conversations also we have added the coversation id as this will help us in refering to the document which led to the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a00f28b5-8ea7-4278-8b49-d014bb470a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB without persistence: data will be transient\n",
      "No embedding_function provided, using default embedding function: SentenceTransformerEmbeddingFunction\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "chroma_client = chromadb.Client()\n",
    "collection = chroma_client.create_collection(name=\"my_collection\")\n",
    "collection.add(\n",
    "    documents=docs,\n",
    "    ids=cov_ids\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb8f96b-e1e5-408c-b27e-ccb779202530",
   "metadata": {},
   "source": [
    "### RAG Pipline defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9fbb5603-b00c-4d31-b487-72942b8de163",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_pipeline(question):\n",
    "    results = collection.query(query_texts=[question],n_results=2)\n",
    "    \n",
    "    prompt = f\"<s> [INST] Aswer the following question in few words \\n \\\n",
    "    Question: {question} \\n Basesd on the Context:\\\n",
    "    {results['documents'][0][0]} \\n {results['documents'][0][1]}  [/INST]\\n Answer: \"\n",
    "    \n",
    "    seq = pipeline(prompt) \n",
    "    x = seq[0]['generated_text'].split(prompt)\n",
    "    \n",
    "    return (x[1],\",\".join(results['ids'][0]).strip(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bf4990de-eb51-4cc6-bbd5-520bb755f6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_pair = pd.read_csv(\"dataset/gen_qa_pair.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7df13d-a810-4015-a257-13823350c95d",
   "metadata": {},
   "source": [
    "### Generating answer for the Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "46522dd7-f4c0-4182-81db-22979d78b4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "97it [04:45,  2.94s/it]\n"
     ]
    }
   ],
   "source": [
    "gen_ans = []\n",
    "relevent_cov = []\n",
    "\n",
    "for _,r in tqdm(qa_pair.iterrows()):\n",
    "    q = r.Question.strip(\"<question> \")\n",
    "    ans,rel_conv = rag_pipeline(q)\n",
    "    gen_ans.append(ans)\n",
    "    relevent_cov.append(rel_conv)\n",
    "\n",
    "qa_pair['gen_ans'] = gen_ans\n",
    "qa_pair['retrived_cov_ids'] = relevent_cov\n",
    "\n",
    "qa_pair.to_csv(\"dataset/gen_qa_ans.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44abd449-f60e-4850-9e2f-4342cba3e9d9",
   "metadata": {},
   "source": [
    "## Evalution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "878716c7-f67f-44a4-82be-ad9d20cda3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "\n",
    "rouge = load('rouge')\n",
    "bertscore = load('bertscore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bd581c5-8249-4572-bf6b-ccd17859a84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dataset/gen_qa_ans.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6af56ea3-52d9-4e72-a337-e94a369f44e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Conv_id</th>\n",
       "      <th>gen_ans</th>\n",
       "      <th>retrived_cov_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;question&gt; Do you like dance?</td>\n",
       "      <td>&lt;ans&gt; Yes, I do.</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes, I like dance. Bruce Lee was a dancer too...</td>\n",
       "      <td>5,61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>&lt;question&gt; Did you know Bruce Lee was a cha ch...</td>\n",
       "      <td>&lt;ans&gt; Yes, he even won a hardcore cha cha cham...</td>\n",
       "      <td>2</td>\n",
       "      <td>Bruce Lee was a cha cha dancer and won a cham...</td>\n",
       "      <td>2,64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;question&gt; Did you know Tupac was a ballet dan...</td>\n",
       "      <td>&lt;ans&gt; Yes, and he even was in the production o...</td>\n",
       "      <td>2</td>\n",
       "      <td>Tupac was a ballet dancer? No, I didn't know ...</td>\n",
       "      <td>64,2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>&lt;question&gt; Do ballet dancers go through a lot ...</td>\n",
       "      <td>&lt;ans&gt; Yes, they go through 4 pairs of shoes a ...</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes, ballet dancers go through many shoes, of...</td>\n",
       "      <td>2,4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>&lt;question&gt; Did you know babies are good at dan...</td>\n",
       "      <td>&lt;ans&gt; Yes, and they smile more when they hit t...</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes, babies are good at dancing. They spontan...</td>\n",
       "      <td>65,2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           Question  \\\n",
       "0           0                      <question> Do you like dance?   \n",
       "1           1  <question> Did you know Bruce Lee was a cha ch...   \n",
       "2           2  <question> Did you know Tupac was a ballet dan...   \n",
       "3           3  <question> Do ballet dancers go through a lot ...   \n",
       "4           4  <question> Did you know babies are good at dan...   \n",
       "\n",
       "                                              Answer  Conv_id  \\\n",
       "0                                   <ans> Yes, I do.        2   \n",
       "1  <ans> Yes, he even won a hardcore cha cha cham...        2   \n",
       "2  <ans> Yes, and he even was in the production o...        2   \n",
       "3  <ans> Yes, they go through 4 pairs of shoes a ...        2   \n",
       "4  <ans> Yes, and they smile more when they hit t...        2   \n",
       "\n",
       "                                             gen_ans retrived_cov_ids  \n",
       "0   Yes, I like dance. Bruce Lee was a dancer too...             5,61  \n",
       "1   Bruce Lee was a cha cha dancer and won a cham...             2,64  \n",
       "2   Tupac was a ballet dancer? No, I didn't know ...             64,2  \n",
       "3   Yes, ballet dancers go through many shoes, of...              2,4  \n",
       "4   Yes, babies are good at dancing. They spontan...             65,2  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "453c5f62-4e7d-49b3-a0e8-42c0d403a7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74c13146-6d83-4a0a-9e40-ffb14284937a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "97it [00:21,  4.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The evalutation of are as follows :\n",
      "*Rouge1: 0.2681507432372196 \n",
      "*RougeL: 0.2287766904620272\n",
      "*BertScore: 0.8748656437569058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate_QA():\n",
    "    rouge_1,rouge_score,bert_score = 0,0,0\n",
    "    for _,x in tqdm(df.iterrows()):\n",
    "        ref = [x.Answer.strip(\"<ans> \")]\n",
    "        pred = [x.gen_ans]\n",
    "        r = rouge.compute(references=ref,predictions=pred)\n",
    "        rouge_score +=r['rougeL']\n",
    "        rouge_1+=r['rouge1']\n",
    "        out = bertscore.compute(references=ref,predictions=pred, lang=\"en\")\n",
    "        bert_score += out['f1'][0]\n",
    "    print(f\"The evalutation of are as follows :\\n*Rouge1: {rouge_1/len(df)} \\n*RougeL: {rouge_score/len(df)}\\n*BertScore: {bert_score/len(df)}\")\n",
    "evaluate_QA()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9e748f-868f-4a15-a750-41f9c6958987",
   "metadata": {},
   "source": [
    "### Results and conclusion\n",
    "\n",
    "The task was quit open ended and hence evalution becomes hard as the question but we have done the task in the following manner. First we generated the QA pair from the Llama 2 model this will serve a benchmark to evalute our RAG pipline. Then we build RAG pipline to perform QA over the conversation which was evaluted with the generated question ans pairs.\n",
    "\n",
    "|Rouge1|RougeL|BertScore|\n",
    "|-|-|-|\n",
    "|0.2681|0.2287|0.8748|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19bc836-0b81-4900-96f9-35c3e69e5ae0",
   "metadata": {},
   "source": [
    "# Future Works\n",
    "1. Try different chunikng methods\n",
    "2. Generate a meaning QA dataset from the conversation \n",
    "3. Ones we have some dataset we can try few short prompting and fine tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6419ede7-54b6-4f4f-8df1-fa16b6da0929",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
